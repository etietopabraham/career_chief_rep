{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First thing we do is setup our config.yaml which holds information about where our data will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Root directory for all artifacts\n",
    "artifacts_root: artifacts\n",
    "\n",
    "# Configuration related to data ingestion\n",
    "data_ingestion:\n",
    "\n",
    "  # Directory where data ingestion artifacts are stored\n",
    "  root_dir: artifacts/data_ingestion\n",
    "\n",
    "  # Path to the local file where the data is already saved\n",
    "  local_data_file: /Users/macbookpro/Documents/Documents - Macbookâ€™s MacBook Pro/thesis/thesis/data/gsearch_jobs.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Entity for Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    \"\"\"\n",
    "    Configuration for data ingestion process.\n",
    "    \n",
    "    Attributes:\n",
    "    - root_dir: Directory where data ingestion artifacts are stored.\n",
    "    - local_data_file: Path to the local file where the data is already saved.\n",
    "    \"\"\"\n",
    "    root_dir: Path\n",
    "    local_data_file: Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Path to main configuration file\n",
    "CONFIG_FILE_PATH = Path('config/config.yaml')\n",
    "\n",
    "# Path to parameters file\n",
    "PARAMS_FILE_PATH = Path('params.yaml')\n",
    "\n",
    "# Path to scheme file\n",
    "SCHEMA_FILE_PATH = Path('schema.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Src Configuration Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.career_chief.constants import *\n",
    "from src.career_chief.utils.common import read_yaml, create_directories\n",
    "from src.career_chief import logger\n",
    "from src.career_chief.entity.config_entity import (DataIngestionConfig)\n",
    "\n",
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    ConfigurationManager manages configurations needed for the data pipeline.\n",
    "\n",
    "    The class reads configuration, parameter, and schema settings from specified files\n",
    "    and provides a set of methods to access these settings. It also takes care of\n",
    "    creating necessary directories defined in the configurations.\n",
    "\n",
    "    Attributes:\n",
    "    - config (dict): Configuration settings.\n",
    "    - params (dict): Parameters for the pipeline.\n",
    "    - schema (dict): Schema information.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 config_filepath = CONFIG_FILE_PATH, \n",
    "                 params_filepath = PARAMS_FILE_PATH, \n",
    "                 schema_filepath = SCHEMA_FILE_PATH) -> None:\n",
    "        \"\"\"\n",
    "        Initialize ConfigurationManager with configurations, parameters, and schema.\n",
    "\n",
    "        Args:\n",
    "        - config_filepath (Path): Path to the configuration file.\n",
    "        - params_filepath (Path): Path to the parameters file.\n",
    "        - schema_filepath (Path): Path to the schema file.\n",
    "\n",
    "        Creates:\n",
    "        - Directories specified in the configuration.\n",
    "        \"\"\"\n",
    "        self.config = self._read_config_file(config_filepath, \"config\")\n",
    "        self.params = self._read_config_file(params_filepath, \"params\")\n",
    "        self.schema = self._read_config_file(schema_filepath, \"initial_schema\")\n",
    "\n",
    "        # Create the directory for storing artifacts if it doesn't exist\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def _read_config_file(self, filepath: str, config_name: str) -> dict:\n",
    "        \"\"\"\n",
    "        Read a configuration file and return its content.\n",
    "\n",
    "        Args:\n",
    "        - filepath (str): Path to the configuration file.\n",
    "        - config_name (str): Name of the configuration (for logging purposes).\n",
    "\n",
    "        Returns:\n",
    "        - dict: Configuration settings.\n",
    "\n",
    "        Raises:\n",
    "        - Exception: If there's an error reading the file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return read_yaml(filepath)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading {config_name} file: {filepath}. Error: {e}\")\n",
    "            raise\n",
    "\n",
    "    \n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        \"\"\"\n",
    "        Extract and return data ingestion configurations as a DataIngestionConfig object.\n",
    "\n",
    "        This method fetches settings related to data ingestion, like directories and file paths,\n",
    "        and returns them as a DataIngestionConfig object.\n",
    "\n",
    "        Returns:\n",
    "        - DataIngestionConfig: Object containing data ingestion configuration settings.\n",
    "\n",
    "        Raises:\n",
    "        - AttributeError: If the 'data_ingestion' attribute does not exist in the config file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            config = self.config.data_ingestion\n",
    "            # Create the root directory for data ingestion if it doesn't already exist\n",
    "            create_directories([config.root_dir])\n",
    "            \n",
    "            return DataIngestionConfig(\n",
    "                root_dir=Path(config.root_dir),\n",
    "                local_data_file=Path(config.local_data_file),\n",
    "            )\n",
    "\n",
    "        except AttributeError as e:\n",
    "            logger.error(\"The 'data_ingestion' attribute does not exist in the config file.\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Components for Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "from src.career_chief import logger\n",
    "from src.career_chief.utils.common import get_size\n",
    "from src.career_chief.entity.config_entity import DataIngestionConfig\n",
    "\n",
    "class DataIngestion:\n",
    "    \"\"\"\n",
    "    DataIngestion handles the process of transferring data from a local directory \n",
    "    to the project's official artifact directories.\n",
    "\n",
    "    The class currently assumes that the data is already present locally, \n",
    "    and focuses on transferring this data to the specified directory.\n",
    "\n",
    "    Attributes:\n",
    "    - config (DataIngestionConfig): Configuration settings for data ingestion.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        \"\"\"\n",
    "        Initialize the DataIngestion component.\n",
    "\n",
    "        Args:\n",
    "        - config (DataIngestionConfig): Configuration settings for data ingestion.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "    def download_data(self):\n",
    "        \"\"\" \n",
    "        Placeholder for downloading data functionality. \n",
    "        Currently, data is assumed to be locally available.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        Placeholder for extracting zip files. \n",
    "        If the data comes as a zip file, this method can be used to extract it.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def read_data_file(self, file_name: str = \"gsearch_jobs.csv\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Read the specified jobs data file into a pandas DataFrame, defaulting to 'gsearch_jobs.csv'.\n",
    "\n",
    "        Args:\n",
    "        - file_name (str, optional): The name of the file to be read. Defaults to \"gsearch_jobs.csv\".\n",
    "\n",
    "        Returns:\n",
    "        - df (pd.DataFrame): DataFrame containing the jobs data.\n",
    "\n",
    "        Raises:\n",
    "        - FileNotFoundError: If the specified data file does not exist in the artifact directory.\n",
    "        \"\"\"\n",
    "        # Construct the path to the data file in the artifact directory\n",
    "        artifact_data_path = Path(self.config.root_dir) / file_name\n",
    "        \n",
    "        # Check if the artifact data file exists\n",
    "        if not artifact_data_path.exists():\n",
    "            logger.error(f\"Artifact data file not found at {artifact_data_path}.\")\n",
    "            raise FileNotFoundError(f\"No file found at {artifact_data_path}\")\n",
    "        \n",
    "        # Read the data file into a pandas DataFrame\n",
    "        df = pd.read_csv(artifact_data_path)\n",
    "        \n",
    "        logger.info(f\"Data file '{file_name}' read into DataFrame. Shape: {df.shape}.\")\n",
    "        return df\n",
    "\n",
    "    def transfer_data(self) -> None:\n",
    "        \"\"\"\n",
    "        Transfer the data from the local directory to the project's artifact directory.\n",
    "\n",
    "        This method ensures that the artifact directory exists, and then transfers \n",
    "        the data file to this directory.\n",
    "\n",
    "        Raises:\n",
    "        - FileNotFoundError: If the local data file does not exist.\n",
    "        \"\"\"\n",
    "        root_dir = Path(self.config.root_dir)\n",
    "        local_data_path = Path(self.config.local_data_file)\n",
    "        \n",
    "        # Check if the local data file exists\n",
    "        if not local_data_path.exists():\n",
    "            logger.error(f\"Local data file not found at {local_data_path}.\")\n",
    "            raise FileNotFoundError(f\"No file found at {local_data_path}\")\n",
    "\n",
    "        # Get the file size using the utility function\n",
    "        file_size = get_size(local_data_path)\n",
    "\n",
    "        # Ensure the transfer directory exists\n",
    "        os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "        # Transfer the file\n",
    "        shutil.copy2(local_data_path, root_dir)\n",
    "        logger.info(f\"Data transferred from {local_data_path} to {root_dir}. File size: {file_size}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-04 12:12:10,315: 41: career_chief_logger: INFO: common:  yaml file: config/config.yaml loaded successfully]\n",
      "[2024-03-04 12:12:10,316: 41: career_chief_logger: INFO: common:  yaml file: params.yaml loaded successfully]\n",
      "[2024-03-04 12:12:10,318: 41: career_chief_logger: INFO: common:  yaml file: schema.yaml loaded successfully]\n",
      "[2024-03-04 12:12:10,319: 64: career_chief_logger: INFO: common:  Created directory at: artifacts]\n",
      "[2024-03-04 12:12:10,320: 61: career_chief_logger: INFO: 222083905:  >>>>>> Reading & Displaying Data <<<<<< \n",
      "\n",
      "x==========x]\n",
      "[2024-03-04 12:12:10,321: 36: career_chief_logger: INFO: 222083905:  Fetching data ingestion configuration...]\n",
      "[2024-03-04 12:12:10,321: 64: career_chief_logger: INFO: common:  Created directory at: artifacts/data_ingestion]\n",
      "[2024-03-04 12:12:10,322: 39: career_chief_logger: INFO: 222083905:  Initializing data ingestion process...]\n",
      "[2024-03-04 12:12:10,322: 42: career_chief_logger: INFO: 222083905:  Reading training data from artifacts/data_ingestion]\n",
      "[2024-03-04 12:12:12,380: 68: career_chief_logger: INFO: 122605097:  Data file 'gsearch_jobs.csv' read into DataFrame. Shape: (37962, 27).]\n",
      "[2024-03-04 12:12:12,380: 46: career_chief_logger: INFO: 222083905:  Displaying the top 10 records of the dataset:]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>via</th>\n",
       "      <th>description</th>\n",
       "      <th>extensions</th>\n",
       "      <th>job_id</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>...</th>\n",
       "      <th>commute_time</th>\n",
       "      <th>salary_pay</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_avg</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "      <th>salary_hourly</th>\n",
       "      <th>salary_yearly</th>\n",
       "      <th>salary_standardized</th>\n",
       "      <th>description_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>In the intersection of compliance and analytic...</td>\n",
       "      <td>['15 hours ago', '101Kâ€“143K a year', 'Work fro...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101Kâ€“143K</td>\n",
       "      <td>a year</td>\n",
       "      <td>122000.0</td>\n",
       "      <td>101000.0</td>\n",
       "      <td>143000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122000.0</td>\n",
       "      <td>122000.0</td>\n",
       "      <td>['sql', 'r', 'python', 'tableau']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ATC</td>\n",
       "      <td>United States</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Job Title: Entry Level Business Analyst / Prod...</td>\n",
       "      <td>['12 hours ago', 'Full-time', 'Health insurance']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Aeronautical Data Analyst</td>\n",
       "      <td>Garmin International, Inc.</td>\n",
       "      <td>Olathe, KS</td>\n",
       "      <td>via Indeed</td>\n",
       "      <td>Overview:\\n\\nWe are seeking a full-time...\\nAe...</td>\n",
       "      <td>['18 hours ago', 'Full-time']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJBZXJvbmF1dGljYWwgRGF0YSBBbm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['sql']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Data Analyst - Consumer Goods - Contract to Hire</td>\n",
       "      <td>Upwork</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via Upwork</td>\n",
       "      <td>Enthusiastic Data Analyst for processing sales...</td>\n",
       "      <td>['12 hours ago', '15â€“25 an hour', 'Work from h...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgLSBDb25zdW...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15â€“25</td>\n",
       "      <td>an hour</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41600.0</td>\n",
       "      <td>['excel', 'power_bi', 'powerpoint']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Data Analyst | Workforce Management</td>\n",
       "      <td>Krispy Kreme</td>\n",
       "      <td>United States</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Overview of Position\\n\\nThis position will be ...</td>\n",
       "      <td>['7 hours ago', '90Kâ€“110K a year', 'Contractor']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgfCBXb3JrZm...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90Kâ€“110K</td>\n",
       "      <td>a year</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>['word', 'excel', 'outlook', 'powerpoint']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37957</th>\n",
       "      <td>37957</td>\n",
       "      <td>600</td>\n",
       "      <td>Marketing Data &amp; BI Analyst II</td>\n",
       "      <td>EDWARD JONES</td>\n",
       "      <td>Houstonia, MO</td>\n",
       "      <td>via My ArkLaMiss Jobs</td>\n",
       "      <td>At Edward Jones, we help clients achieve their...</td>\n",
       "      <td>['23 hours ago', '76,798â€“130,764 a year', 'Ful...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJNYXJrZXRpbmcgRGF0YSBcdTAwMj...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76798â€“130764</td>\n",
       "      <td>a year</td>\n",
       "      <td>103781.0</td>\n",
       "      <td>76798.0</td>\n",
       "      <td>130764.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103781.0</td>\n",
       "      <td>103781.0</td>\n",
       "      <td>['python', 'snowflake', 'tableau', 'excel', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37958</th>\n",
       "      <td>37958</td>\n",
       "      <td>601</td>\n",
       "      <td>Lead-Data Analyst</td>\n",
       "      <td>EDWARD JONES</td>\n",
       "      <td>Marshfield, MO</td>\n",
       "      <td>via My ArkLaMiss Jobs</td>\n",
       "      <td>At Edward Jones, we help clients achieve their...</td>\n",
       "      <td>['23 hours ago', '106,916â€“182,047 a year', 'Fu...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJMZWFkLURhdGEgQW5hbHlzdCIsIm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106916â€“182047</td>\n",
       "      <td>a year</td>\n",
       "      <td>144481.5</td>\n",
       "      <td>106916.0</td>\n",
       "      <td>182047.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144481.5</td>\n",
       "      <td>144481.5</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37959</th>\n",
       "      <td>37959</td>\n",
       "      <td>602</td>\n",
       "      <td>Lead-Data Analyst</td>\n",
       "      <td>EDWARD JONES</td>\n",
       "      <td>High Point, MO</td>\n",
       "      <td>via My ArkLaMiss Jobs</td>\n",
       "      <td>At Edward Jones, we help clients achieve their...</td>\n",
       "      <td>['23 hours ago', '106,916â€“182,047 a year', 'Fu...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJMZWFkLURhdGEgQW5hbHlzdCIsIm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106916â€“182047</td>\n",
       "      <td>a year</td>\n",
       "      <td>144481.5</td>\n",
       "      <td>106916.0</td>\n",
       "      <td>182047.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144481.5</td>\n",
       "      <td>144481.5</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37960</th>\n",
       "      <td>37960</td>\n",
       "      <td>603</td>\n",
       "      <td>Lead-Data Analyst</td>\n",
       "      <td>EDWARD JONES</td>\n",
       "      <td>Calhoun, MO</td>\n",
       "      <td>via My ArkLaMiss Jobs</td>\n",
       "      <td>At Edward Jones, we help clients achieve their...</td>\n",
       "      <td>['23 hours ago', '106,916â€“182,047 a year', 'Fu...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJMZWFkLURhdGEgQW5hbHlzdCIsIm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106916â€“182047</td>\n",
       "      <td>a year</td>\n",
       "      <td>144481.5</td>\n",
       "      <td>106916.0</td>\n",
       "      <td>182047.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144481.5</td>\n",
       "      <td>144481.5</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37961</th>\n",
       "      <td>37961</td>\n",
       "      <td>604</td>\n",
       "      <td>Institutional Credit Management - Lending Data...</td>\n",
       "      <td>Citi</td>\n",
       "      <td>United States</td>\n",
       "      <td>via My ArkLaMiss Jobs</td>\n",
       "      <td>The Institutional Credit Management (ICM) grou...</td>\n",
       "      <td>['24 hours ago', '105,850â€“158,780 a year', 'Fu...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJJbnN0aXR1dGlvbmFsIENyZWRpdC...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105850â€“158780</td>\n",
       "      <td>a year</td>\n",
       "      <td>132315.0</td>\n",
       "      <td>105850.0</td>\n",
       "      <td>158780.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132315.0</td>\n",
       "      <td>132315.0</td>\n",
       "      <td>['cognos', 'tableau']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37962 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  index                                              title  \\\n",
       "0               0      0                                       Data Analyst   \n",
       "1               1      1                                       Data Analyst   \n",
       "2               2      2                          Aeronautical Data Analyst   \n",
       "3               3      3   Data Analyst - Consumer Goods - Contract to Hire   \n",
       "4               4      4                Data Analyst | Workforce Management   \n",
       "...           ...    ...                                                ...   \n",
       "37957       37957    600                     Marketing Data & BI Analyst II   \n",
       "37958       37958    601                                  Lead-Data Analyst   \n",
       "37959       37959    602                                  Lead-Data Analyst   \n",
       "37960       37960    603                                  Lead-Data Analyst   \n",
       "37961       37961    604  Institutional Credit Management - Lending Data...   \n",
       "\n",
       "                     company_name            location                    via  \\\n",
       "0                            Meta           Anywhere            via LinkedIn   \n",
       "1                             ATC    United States              via LinkedIn   \n",
       "2      Garmin International, Inc.       Olathe, KS                via Indeed   \n",
       "3                          Upwork           Anywhere              via Upwork   \n",
       "4                    Krispy Kreme    United States              via LinkedIn   \n",
       "...                           ...                 ...                    ...   \n",
       "37957                EDWARD JONES       Houstonia, MO  via My ArkLaMiss Jobs   \n",
       "37958                EDWARD JONES      Marshfield, MO  via My ArkLaMiss Jobs   \n",
       "37959                EDWARD JONES      High Point, MO  via My ArkLaMiss Jobs   \n",
       "37960                EDWARD JONES         Calhoun, MO  via My ArkLaMiss Jobs   \n",
       "37961                        Citi       United States  via My ArkLaMiss Jobs   \n",
       "\n",
       "                                             description  \\\n",
       "0      In the intersection of compliance and analytic...   \n",
       "1      Job Title: Entry Level Business Analyst / Prod...   \n",
       "2      Overview:\\n\\nWe are seeking a full-time...\\nAe...   \n",
       "3      Enthusiastic Data Analyst for processing sales...   \n",
       "4      Overview of Position\\n\\nThis position will be ...   \n",
       "...                                                  ...   \n",
       "37957  At Edward Jones, we help clients achieve their...   \n",
       "37958  At Edward Jones, we help clients achieve their...   \n",
       "37959  At Edward Jones, we help clients achieve their...   \n",
       "37960  At Edward Jones, we help clients achieve their...   \n",
       "37961  The Institutional Credit Management (ICM) grou...   \n",
       "\n",
       "                                              extensions  \\\n",
       "0      ['15 hours ago', '101Kâ€“143K a year', 'Work fro...   \n",
       "1      ['12 hours ago', 'Full-time', 'Health insurance']   \n",
       "2                          ['18 hours ago', 'Full-time']   \n",
       "3      ['12 hours ago', '15â€“25 an hour', 'Work from h...   \n",
       "4       ['7 hours ago', '90Kâ€“110K a year', 'Contractor']   \n",
       "...                                                  ...   \n",
       "37957  ['23 hours ago', '76,798â€“130,764 a year', 'Ful...   \n",
       "37958  ['23 hours ago', '106,916â€“182,047 a year', 'Fu...   \n",
       "37959  ['23 hours ago', '106,916â€“182,047 a year', 'Fu...   \n",
       "37960  ['23 hours ago', '106,916â€“182,047 a year', 'Fu...   \n",
       "37961  ['24 hours ago', '105,850â€“158,780 a year', 'Fu...   \n",
       "\n",
       "                                                  job_id  \\\n",
       "0      eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...   \n",
       "1      eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...   \n",
       "2      eyJqb2JfdGl0bGUiOiJBZXJvbmF1dGljYWwgRGF0YSBBbm...   \n",
       "3      eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgLSBDb25zdW...   \n",
       "4      eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgfCBXb3JrZm...   \n",
       "...                                                  ...   \n",
       "37957  eyJqb2JfdGl0bGUiOiJNYXJrZXRpbmcgRGF0YSBcdTAwMj...   \n",
       "37958  eyJqb2JfdGl0bGUiOiJMZWFkLURhdGEgQW5hbHlzdCIsIm...   \n",
       "37959  eyJqb2JfdGl0bGUiOiJMZWFkLURhdGEgQW5hbHlzdCIsIm...   \n",
       "37960  eyJqb2JfdGl0bGUiOiJMZWFkLURhdGEgQW5hbHlzdCIsIm...   \n",
       "37961  eyJqb2JfdGl0bGUiOiJJbnN0aXR1dGlvbmFsIENyZWRpdC...   \n",
       "\n",
       "                                               thumbnail  ... commute_time  \\\n",
       "0      https://encrypted-tbn0.gstatic.com/images?q=tb...  ...          NaN   \n",
       "1      https://encrypted-tbn0.gstatic.com/images?q=tb...  ...          NaN   \n",
       "2                                                    NaN  ...          NaN   \n",
       "3                                                    NaN  ...          NaN   \n",
       "4      https://encrypted-tbn0.gstatic.com/images?q=tb...  ...          NaN   \n",
       "...                                                  ...  ...          ...   \n",
       "37957                                                NaN  ...          NaN   \n",
       "37958                                                NaN  ...          NaN   \n",
       "37959                                                NaN  ...          NaN   \n",
       "37960                                                NaN  ...          NaN   \n",
       "37961  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...          NaN   \n",
       "\n",
       "          salary_pay salary_rate salary_avg salary_min salary_max  \\\n",
       "0          101Kâ€“143K      a year   122000.0   101000.0   143000.0   \n",
       "1                NaN         NaN        NaN        NaN        NaN   \n",
       "2                NaN         NaN        NaN        NaN        NaN   \n",
       "3              15â€“25     an hour       20.0       15.0       25.0   \n",
       "4           90Kâ€“110K      a year   100000.0    90000.0   110000.0   \n",
       "...              ...         ...        ...        ...        ...   \n",
       "37957   76798â€“130764      a year   103781.0    76798.0   130764.0   \n",
       "37958  106916â€“182047      a year   144481.5   106916.0   182047.0   \n",
       "37959  106916â€“182047      a year   144481.5   106916.0   182047.0   \n",
       "37960  106916â€“182047      a year   144481.5   106916.0   182047.0   \n",
       "37961  105850â€“158780      a year   132315.0   105850.0   158780.0   \n",
       "\n",
       "      salary_hourly  salary_yearly salary_standardized  \\\n",
       "0               NaN       122000.0            122000.0   \n",
       "1               NaN            NaN                 NaN   \n",
       "2               NaN            NaN                 NaN   \n",
       "3              20.0            NaN             41600.0   \n",
       "4               NaN       100000.0            100000.0   \n",
       "...             ...            ...                 ...   \n",
       "37957           NaN       103781.0            103781.0   \n",
       "37958           NaN       144481.5            144481.5   \n",
       "37959           NaN       144481.5            144481.5   \n",
       "37960           NaN       144481.5            144481.5   \n",
       "37961           NaN       132315.0            132315.0   \n",
       "\n",
       "                                      description_tokens  \n",
       "0                      ['sql', 'r', 'python', 'tableau']  \n",
       "1                                                     []  \n",
       "2                                                ['sql']  \n",
       "3                    ['excel', 'power_bi', 'powerpoint']  \n",
       "4             ['word', 'excel', 'outlook', 'powerpoint']  \n",
       "...                                                  ...  \n",
       "37957  ['python', 'snowflake', 'tableau', 'excel', 'p...  \n",
       "37958                                                 []  \n",
       "37959                                                 []  \n",
       "37960                                                 []  \n",
       "37961                              ['cognos', 'tableau']  \n",
       "\n",
       "[37962 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from src.career_chief.config.configuration import ConfigurationManager\n",
    "# from src.career_chief.components.data_ingestion import DataIngestion\n",
    "\n",
    "from src.career_chief import logger\n",
    "\n",
    "class DataIngestionPipeline:\n",
    "\n",
    "    STAGE_NAME = \"Data Ingestion Stage\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.config_manager = ConfigurationManager()\n",
    "\n",
    "    def run_data_ingestion(self):\n",
    "        \"\"\"\n",
    "        Main method to run the data ingestion process.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Fetching data ingestion configuration...\")\n",
    "            data_ingestion_config = self.config_manager.get_data_ingestion_config()\n",
    "            \n",
    "            logger.info(\"Initializing data ingestion process...\")\n",
    "            data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "            \n",
    "            logger.info(f\"Copying training data from {data_ingestion_config.local_data_file} to {data_ingestion_config.root_dir}...\")\n",
    "            data_ingestion.transfer_data()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.exception(\"An error occurred during the data ingestion process.\")\n",
    "            raise e\n",
    "        \n",
    "    def show_data(self):\n",
    "        \"\"\"\n",
    "        Main method to run the data ingestion process and display the top 10 records of the dataset in a nicely formatted manner using IPython's display in Jupyter notebooks.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Fetching data ingestion configuration...\")\n",
    "            data_ingestion_config = self.config_manager.get_data_ingestion_config()\n",
    "            \n",
    "            logger.info(\"Initializing data ingestion process...\")\n",
    "            data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "            \n",
    "            logger.info(f\"Reading training data from {data_ingestion_config.root_dir}\")\n",
    "            df = data_ingestion.read_data_file()  # Capture the returned DataFrame\n",
    "            \n",
    "            # Use IPython's display to show the top 10 records of the DataFrame\n",
    "            logger.info(\"Displaying the top 10 records of the dataset:\")\n",
    "            display(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.exception(\"An error occurred during the data ingestion process.\")\n",
    "            raise e\n",
    "        \n",
    "    def run_pipeline(self):\n",
    "        \"\"\"\n",
    "        Run the data ingestion training pipeline.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # logger.info(f\">>>>>> Stage: {DataIngestionPipeline.STAGE_NAME} started <<<<<<\")\n",
    "            # self.run_data_ingestion()\n",
    "            # logger.info(f\">>>>>> Stage {DataIngestionPipeline.STAGE_NAME} completed <<<<<< \\n\\nx==========x\")\n",
    "            logger.info(\">>>>>> Reading & Displaying Data <<<<<< \\n\\nx==========x\")\n",
    "            self.show_data()\n",
    "\n",
    "        except Exception as e:\n",
    "            # No need to log the exception here since it's already logged in the run_data_ingestion method.\n",
    "            raise e\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pipeline = DataIngestionPipeline()\n",
    "    pipeline.run_pipeline()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "career_chief_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
