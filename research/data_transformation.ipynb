{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/macbookpro/Documents/Documents - Macbookâ€™s MacBook Pro/career/career_chief_rep'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure config.yaml which holds information about where our data will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration related to data transformation\n",
    "data_transformation:\n",
    "  # Directory where data transformation results and artifacts are stored\n",
    "  root_dir: artifacts/data_transformation\n",
    "  \n",
    "  # Path to the ingested data file that will be used for validation\n",
    "  data_source_file: artifacts/data_ingestion/gsearch_jobs.csv\n",
    "\n",
    "  # Path to data validation status\n",
    "  data_validation: artifacts/data_validation/status.txt\n",
    "\n",
    "  # Path to normalization dictionary\n",
    "  normalization_dict: artifacts/data_transformation/normalization_dict.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    \"\"\"\n",
    "    Configuration for the data transformation process.\n",
    "    \n",
    "    This configuration class captures the necessary paths and directories \n",
    "    required for the transformation of data post-ingestion and pre-model training.\n",
    "    \n",
    "    Attributes:\n",
    "    - root_dir: Directory where data transformation results and artifacts are stored.\n",
    "    - data_source_file: Path to the file where the ingested data is stored that needs to be transformed.\n",
    "    \"\"\"\n",
    "    \n",
    "    root_dir: Path  # Directory for storing transformation results and related artifacts\n",
    "    data_source_file: Path  # Path to the ingested data file for transformation\n",
    "    data_validation: Path # Path to the validated output file\n",
    "    normalization_dict: Path # Path to our abbreviation normalized dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the Configuration Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.career_chief.constants import *\n",
    "from src.career_chief.utils.common import read_yaml, create_directories\n",
    "from src.career_chief import logger\n",
    "from src.career_chief.entity.config_entity import (DataIngestionConfig, DataValidationConfig)\n",
    "\n",
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    ConfigurationManager manages configurations needed for the data pipeline.\n",
    "\n",
    "    The class reads configuration, parameter, and schema settings from specified files\n",
    "    and provides a set of methods to access these settings. It also takes care of\n",
    "    creating necessary directories defined in the configurations.\n",
    "\n",
    "    Attributes:\n",
    "    - config (dict): Configuration settings.\n",
    "    - params (dict): Parameters for the pipeline.\n",
    "    - schema (dict): Schema information.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 config_filepath = CONFIG_FILE_PATH, \n",
    "                 params_filepath = PARAMS_FILE_PATH, \n",
    "                 schema_filepath = SCHEMA_FILE_PATH) -> None:\n",
    "        \"\"\"\n",
    "        Initialize ConfigurationManager with configurations, parameters, and schema.\n",
    "\n",
    "        Args:\n",
    "        - config_filepath (Path): Path to the configuration file.\n",
    "        - params_filepath (Path): Path to the parameters file.\n",
    "        - schema_filepath (Path): Path to the schema file.\n",
    "\n",
    "        Creates:\n",
    "        - Directories specified in the configuration.\n",
    "        \"\"\"\n",
    "        self.config = self._read_config_file(config_filepath, \"config\")\n",
    "        self.params = self._read_config_file(params_filepath, \"params\")\n",
    "        self.schema = self._read_config_file(schema_filepath, \"schema\")\n",
    "\n",
    "        # Create the directory for storing artifacts if it doesn't exist\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def _read_config_file(self, filepath: str, config_name: str) -> dict:\n",
    "        \"\"\"\n",
    "        Read a configuration file and return its content.\n",
    "\n",
    "        Args:\n",
    "        - filepath (str): Path to the configuration file.\n",
    "        - config_name (str): Name of the configuration (for logging purposes).\n",
    "\n",
    "        Returns:\n",
    "        - dict: Configuration settings.\n",
    "\n",
    "        Raises:\n",
    "        - Exception: If there's an error reading the file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return read_yaml(filepath)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading {config_name} file: {filepath}. Error: {e}\")\n",
    "            raise\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        \"\"\"\n",
    "        Extract and return data transformation configurations as a DataTransformationConfig object.\n",
    "\n",
    "        This method fetches settings related to data transformation, like directories and file paths,\n",
    "        and returns them as a DataTransformationConfig object.\n",
    "\n",
    "        Returns:\n",
    "        - DataTransformationConfig: Object containing data transformation configuration settings.\n",
    "\n",
    "        Raises:\n",
    "        - AttributeError: If the 'data_transformation' attribute does not exist in the config file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            config = self.config.data_transformation\n",
    "            \n",
    "            # Ensure the root directory for data transformation exists\n",
    "            create_directories([config.root_dir])\n",
    "\n",
    "            # Construct and return the DataTransformationConfig object\n",
    "            return DataTransformationConfig(\n",
    "                root_dir=Path(config.root_dir),\n",
    "                data_source_file=Path(config.data_source_file),\n",
    "                data_validation=Path(config.data_validation),\n",
    "                normalization_dict=Path(config.normalization_dict),\n",
    "            )\n",
    "\n",
    "        except AttributeError as e:\n",
    "            # Log the error and re-raise the exception for handling by the caller\n",
    "            logger.error(\"The 'data_transformation' attribute does not exist in the config file.\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-11 17:15:25,073: 58: datasets: INFO: config:  PyTorch version 2.1.2 available.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import os\n",
    "import json\n",
    "from src.career_chief import logger\n",
    "\n",
    "class DataTransformation:\n",
    "    \"\"\"\n",
    "    Preprocesses technical resume data for NLP tasks, including noise removal, technical term normalization,\n",
    "    tokenization, and named entity recognition (NER). Processes are optimized for efficiency and clarity.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Initializes the DataTransformation class with configuration settings.\n",
    "\n",
    "        Args:\n",
    "            config (object): Configuration object containing necessary settings such as file paths and model details.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")  # Load spaCy English model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-large-NER\")  # Hugging Face tokenizer\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-large-NER\")  # NER model\n",
    "        self.nlp_pipeline = pipeline(\"ner\", model=self.model, tokenizer=self.tokenizer)  # NER pipeline\n",
    "        self.normalization_dict = self._load_normalization_dict()  # Load normalization dictionary\n",
    "        self.df = self._load_data()  # Load dataset\n",
    "        logger.info(\"DataTransformation initialized with provided configuration.\")\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"Loads data from the specified CSV file.\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(self.config.data_source_file)\n",
    "            logger.info(\"Data loaded successfully from {}\".format(self.config.data_source_file))\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logger.error(\"Failed to load data from {}: {}\".format(self.config.data_source_file, e))\n",
    "            raise\n",
    "\n",
    "    def _load_normalization_dict(self):\n",
    "        \"\"\"Loads the normalization dictionary from a JSON file.\"\"\"\n",
    "        try:\n",
    "            with open(self.config.normalization_dict) as f:\n",
    "                normalization_dict = json.load(f)\n",
    "            logger.info(\"Normalization dictionary loaded successfully.\")\n",
    "            return normalization_dict\n",
    "        except Exception as e:\n",
    "            logger.error(\"Failed to load normalization dictionary: {}\".format(e))\n",
    "            raise\n",
    "\n",
    "    def preprocess_and_transform(self):\n",
    "        \"\"\"Executes the full preprocessing and transformation pipeline.\"\"\"\n",
    "        logger.info(\"Starting preprocessing and transformation pipeline.\")\n",
    "        self._remove_noise()\n",
    "        self._normalize_technical_terms()\n",
    "        self._tokenize_text()\n",
    "        self._apply_ner()\n",
    "        self._split_data()\n",
    "        logger.info(\"Preprocessing and transformation pipeline completed.\")\n",
    "\n",
    "    def _remove_noise(self):\n",
    "        \"\"\"Removes noise such as special characters from the text descriptions.\"\"\"\n",
    "        tqdm.pandas(desc=\"Removing Noise\")\n",
    "        self.df['cleaned_text'] = self.df['description'].progress_apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "        logger.info(\"Noise removed from text.\")\n",
    "\n",
    "    def _normalize_technical_terms(self):\n",
    "        \"\"\"Normalizes technical terms using the provided normalization dictionary.\"\"\"\n",
    "        tqdm.pandas(desc=\"Normalizing Technical Terms\")\n",
    "        def normalize_text(text):\n",
    "            for abbr, full_form in self.normalization_dict.items():\n",
    "                text = re.sub(r'\\b{}\\b'.format(abbr), full_form, text, flags=re.IGNORECASE)\n",
    "            return text\n",
    "        self.df['cleaned_text'] = self.df['cleaned_text'].progress_apply(normalize_text)\n",
    "        logger.info(\"Technical terms normalized.\")\n",
    "\n",
    "    def _tokenize_text(self):\n",
    "        \"\"\"Tokenizes the cleaned text with automatic truncation to the maximum sequence length.\"\"\"\n",
    "        max_token_length = 512\n",
    "        tqdm.pandas(desc=\"Tokenizing Text\")\n",
    "        self.df['tokens'] = self.df['cleaned_text'].progress_apply(\n",
    "            lambda x: self.tokenizer(x, truncation=True, max_length=max_token_length)['input_ids'])\n",
    "        logger.info(\"Text tokenized with automatic truncation to max length.\")\n",
    "\n",
    "\n",
    "    def _apply_ner(self):\n",
    "        \"\"\"Applies named entity recognition (NER) to identify entities within the text.\"\"\"\n",
    "        tqdm.pandas(desc=\"Applying NER\")\n",
    "        self.df['ner_results'] = self.df['cleaned_text'].progress_apply(self.nlp_pipeline)\n",
    "        logger.info(\"NER applied to text.\")\n",
    "\n",
    "    def _split_data(self, test_size=0.2, val_size=0.1):\n",
    "        \"\"\"Splits the dataset into training, validation, and testing sets.\"\"\"\n",
    "        train_val, test = train_test_split(self.df, test_size=test_size)\n",
    "        train, val = train_test_split(train_val, test_size=val_size / (1 - test_size))\n",
    "        self.train_data, self.val_data, self.test_data = train, val, test\n",
    "        logger.info(\"Data split into training, validation, and test sets.\")\n",
    "\n",
    "    def save_data(self, dataset, filename):\n",
    "        \"\"\"Saves the processed dataset to a CSV file.\"\"\"\n",
    "        filepath = os.path.join(self.config.root_dir, filename)\n",
    "        try:\n",
    "            dataset.to_csv(filepath, index=False)\n",
    "            logger.info(\"Dataset saved to {}\".format(filepath))\n",
    "        except Exception as e:\n",
    "            logger.error(\"Failed to save dataset to {}: {}\".format(filepath, e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-11 17:17:29,860: 41: career_chief_logger: INFO: common:  yaml file: config/config.yaml loaded successfully]\n",
      "[2024-03-11 17:17:29,862: 41: career_chief_logger: INFO: common:  yaml file: params.yaml loaded successfully]\n",
      "[2024-03-11 17:17:29,865: 41: career_chief_logger: INFO: common:  yaml file: schema.yaml loaded successfully]\n",
      "[2024-03-11 17:17:29,865: 64: career_chief_logger: INFO: common:  Created directory at: artifacts]\n",
      "[2024-03-11 17:17:29,866: 64: career_chief_logger: INFO: common:  Created directory at: artifacts/data_transformation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-large-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-11 17:17:35,150: 49: career_chief_logger: INFO: 2851148029:  Normalization dictionary loaded successfully.]\n",
      "[2024-03-11 17:17:36,973: 38: career_chief_logger: INFO: 2851148029:  Data loaded successfully from artifacts/data_ingestion/gsearch_jobs.csv]\n",
      "[2024-03-11 17:17:36,974: 32: career_chief_logger: INFO: 2851148029:  DataTransformation initialized with provided configuration.]\n",
      "[2024-03-11 17:17:36,974: 21: career_chief_logger: INFO: 3498145602:  Data Transformation Pipeline initialized.]\n",
      "[2024-03-11 17:17:36,974: 32: career_chief_logger: INFO: 3498145602:  Data Transformation Pipeline: Starting the data transformation process.]\n",
      "[2024-03-11 17:17:36,975: 57: career_chief_logger: INFO: 2851148029:  Starting preprocessing and transformation pipeline.]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bab73dcf0a4e69bc35407414bde13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Removing Noise:   0%|          | 0/37962 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-11 17:17:38,271: 69: career_chief_logger: INFO: 2851148029:  Noise removed from text.]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3fa275e14894a0f9325da443a101252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Normalizing Technical Terms:   0%|          | 0/37962 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-11 17:21:07,037: 79: career_chief_logger: INFO: 2851148029:  Technical terms normalized.]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8786b4f5b8d4926949af265f37ebfd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing Text:   0%|          | 0/37962 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-11 17:21:49,131: 87: career_chief_logger: INFO: 2851148029:  Text tokenized and truncated to max length.]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28d8214da14472492db7eab75435fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying NER:   0%|          | 0/37962 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-12 01:12:29,558: 93: career_chief_logger: INFO: 2851148029:  NER applied to text.]\n",
      "[2024-03-12 01:12:55,321: 100: career_chief_logger: INFO: 2851148029:  Data split into training, validation, and test sets.]\n",
      "[2024-03-12 01:12:55,333: 63: career_chief_logger: INFO: 2851148029:  Preprocessing and transformation pipeline completed.]\n",
      "[2024-03-12 01:13:34,054: 60: career_chief_logger: INFO: 3498145602:  Transformed dataset saved to artifacts/data_transformation/train_data.csv]\n",
      "[2024-03-12 01:13:40,586: 60: career_chief_logger: INFO: 3498145602:  Transformed dataset saved to artifacts/data_transformation/val_data.csv]\n",
      "[2024-03-12 01:13:56,106: 60: career_chief_logger: INFO: 3498145602:  Transformed dataset saved to artifacts/data_transformation/test_data.csv]\n",
      "[2024-03-12 01:14:19,306: 46: career_chief_logger: INFO: 3498145602:  Data Transformation Pipeline: Data transformation process completed.]\n",
      "[2024-03-12 01:14:19,318: 68: career_chief_logger: INFO: 3498145602:  Training dataset size: 26572]\n",
      "[2024-03-12 01:14:19,319: 69: career_chief_logger: INFO: 3498145602:  Validation dataset size: 3797]\n",
      "[2024-03-12 01:14:19,319: 70: career_chief_logger: INFO: 3498145602:  Testing dataset size: 7593]\n"
     ]
    }
   ],
   "source": [
    "from src.career_chief.entity.config_entity import DataTransformationConfig  # Import the configuration class\n",
    "from src.career_chief import logger\n",
    "from datasets import Dataset\n",
    "import os\n",
    "\n",
    "class DataTransformationPipeline:\n",
    "    \"\"\"\n",
    "    Orchestrates the data transformation process including preprocessing, NER,\n",
    "    and splitting the data into training, validation, and testing datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    STAGE_NAME = \"Data Transformation Pipeline\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the DataTransformationPipeline with configurations obtained from the ConfigurationManager.\n",
    "        \"\"\"\n",
    "        self.config_manager = ConfigurationManager()\n",
    "        transformation_config = self.config_manager.get_data_transformation_config()\n",
    "        self.data_transformation = DataTransformation(transformation_config)\n",
    "        logger.info(\"{} initialized.\".format(self.STAGE_NAME))\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        \"\"\"\n",
    "        Executes the data transformation process and returns transformed datasets.\n",
    "        \n",
    "        Returns:\n",
    "            train_ds (Dataset): The training dataset.\n",
    "            val_ds (Dataset): The validation dataset.\n",
    "            test_ds (Dataset): The testing dataset.\n",
    "        \"\"\"\n",
    "        logger.info(f\"{self.STAGE_NAME}: Starting the data transformation process.\")\n",
    "        # Preprocess and transform data\n",
    "        self.data_transformation.preprocess_and_transform()\n",
    "\n",
    "        # Saving the processed data\n",
    "        self.save_transformed_data(self.data_transformation.train_data, 'train_data.csv')\n",
    "        self.save_transformed_data(self.data_transformation.val_data, 'val_data.csv')\n",
    "        self.save_transformed_data(self.data_transformation.test_data, 'test_data.csv')\n",
    "        \n",
    "        # Convert to Hugging Face datasets for compatibility\n",
    "        train_ds = Dataset.from_pandas(self.data_transformation.train_data)\n",
    "        val_ds = Dataset.from_pandas(self.data_transformation.val_data)\n",
    "        test_ds = Dataset.from_pandas(self.data_transformation.test_data)\n",
    "\n",
    "        logger.info(f\"{self.STAGE_NAME}: Data transformation process completed.\")\n",
    "        return train_ds, val_ds, test_ds\n",
    "\n",
    "    def save_transformed_data(self, dataset, filename):\n",
    "        \"\"\"\n",
    "        Saves the transformed dataset to a CSV file in the specified directory.\n",
    "        \n",
    "        Args:\n",
    "            dataset (pd.DataFrame): The dataset to save.\n",
    "            filename (str): The filename for the saved dataset.\n",
    "        \"\"\"\n",
    "        filepath = os.path.join(self.data_transformation.config.root_dir, filename)\n",
    "        try:\n",
    "            dataset.to_csv(filepath, index=False)\n",
    "            logger.info(f\"Transformed dataset saved to {filepath}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save transformed dataset to {filepath}: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pipeline = DataTransformationPipeline()\n",
    "    train_ds, val_ds, test_ds = pipeline.run_pipeline()\n",
    "    # Further processing or model training can now be performed on these datasets\n",
    "    logger.info(f\"Training dataset size: {len(train_ds)}\")\n",
    "    logger.info(f\"Validation dataset size: {len(val_ds)}\")\n",
    "    logger.info(f\"Testing dataset size: {len(test_ds)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training dataset:\n",
      "Shape: (26572, 30)\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>via</th>\n",
       "      <th>description</th>\n",
       "      <th>extensions</th>\n",
       "      <th>job_id</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>...</th>\n",
       "      <th>salary_avg</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "      <th>salary_hourly</th>\n",
       "      <th>salary_yearly</th>\n",
       "      <th>salary_standardized</th>\n",
       "      <th>description_tokens</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30200</td>\n",
       "      <td>827</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Planet Technology</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Our Client is looking for a full-time Sr. Data...</td>\n",
       "      <td>['10 hours ago', 'Work from home', 'Full-time']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBBbmFseXN0Ii...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['excel', 'bigquery', 'redshift', 'sql', 'powe...</td>\n",
       "      <td>Our Client is looking for a fulltime Sr Data A...</td>\n",
       "      <td>['Our', 'C', '##lient', 'is', 'looking', 'for'...</td>\n",
       "      <td>[{'entity': 'B-MISC', 'score': 0.6366868, 'ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13682</td>\n",
       "      <td>652</td>\n",
       "      <td>Data Analysis</td>\n",
       "      <td>Upwork</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via Upwork</td>\n",
       "      <td>We are seeking a skilled data analyst to join ...</td>\n",
       "      <td>['19 hours ago', 'Work from home', 'Contractor...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c2lzIiwiaHRpZG...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>We are seeking a skilled data analyst to join ...</td>\n",
       "      <td>['We', 'are', 'seeking', 'a', 'skilled', 'data...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3935</td>\n",
       "      <td>1901</td>\n",
       "      <td>Google Analytics GA4 Adjustment</td>\n",
       "      <td>Upwork</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via Upwork</td>\n",
       "      <td>We are seeking a skilled professional to adjus...</td>\n",
       "      <td>['12 hours ago', '10â€“46 an hour', 'Work from h...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJHb29nbGUgQW5hbHl0aWNzIEdBNC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58240.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>We are seeking a skilled professional to adjus...</td>\n",
       "      <td>['We', 'are', 'seeking', 'a', 'skilled', 'prof...</td>\n",
       "      <td>[{'entity': 'B-MISC', 'score': 0.8648094, 'ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26125</td>\n",
       "      <td>2684</td>\n",
       "      <td>Data analyst sql and etl data management</td>\n",
       "      <td>Upwork</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via Upwork</td>\n",
       "      <td>It's totally about data analysis and looking f...</td>\n",
       "      <td>['14 hours ago', '8â€“15 an hour', 'Work from ho...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIGFuYWx5c3Qgc3FsIGFuZC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23920.0</td>\n",
       "      <td>['excel', 'sql']</td>\n",
       "      <td>Its totally about data analysis and looking fo...</td>\n",
       "      <td>['Its', 'totally', 'about', 'data', 'analysis'...</td>\n",
       "      <td>[{'entity': 'B-MISC', 'score': 0.8927205, 'ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24366</td>\n",
       "      <td>925</td>\n",
       "      <td>Reporting and Data Enablement Analyst (Remote)</td>\n",
       "      <td>Vail Resorts</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via Indeed</td>\n",
       "      <td>As a leading mountain resort operator with ove...</td>\n",
       "      <td>['16 hours ago', '82,800â€“106,425 a year', 'Wor...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJSZXBvcnRpbmcgYW5kIERhdGEgRW...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>94612.5</td>\n",
       "      <td>82800.0</td>\n",
       "      <td>106425.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94612.5</td>\n",
       "      <td>94612.5</td>\n",
       "      <td>['jira', 'python', 'atlassian', 'snowflake', '...</td>\n",
       "      <td>As a leading mountain resort operator with ove...</td>\n",
       "      <td>['As', 'a', 'leading', 'mountain', 'resort', '...</td>\n",
       "      <td>[{'entity': 'B-MISC', 'score': 0.63972175, 'in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                                           title  \\\n",
       "0       30200    827                             Senior Data Analyst   \n",
       "1       13682    652                                   Data Analysis   \n",
       "2        3935   1901                 Google Analytics GA4 Adjustment   \n",
       "3       26125   2684        Data analyst sql and etl data management   \n",
       "4       24366    925  Reporting and Data Enablement Analyst (Remote)   \n",
       "\n",
       "        company_name    location           via  \\\n",
       "0  Planet Technology    Anywhere  via LinkedIn   \n",
       "1             Upwork   Anywhere     via Upwork   \n",
       "2             Upwork   Anywhere     via Upwork   \n",
       "3             Upwork   Anywhere     via Upwork   \n",
       "4       Vail Resorts    Anywhere    via Indeed   \n",
       "\n",
       "                                         description  \\\n",
       "0  Our Client is looking for a full-time Sr. Data...   \n",
       "1  We are seeking a skilled data analyst to join ...   \n",
       "2  We are seeking a skilled professional to adjus...   \n",
       "3  It's totally about data analysis and looking f...   \n",
       "4  As a leading mountain resort operator with ove...   \n",
       "\n",
       "                                          extensions  \\\n",
       "0    ['10 hours ago', 'Work from home', 'Full-time']   \n",
       "1  ['19 hours ago', 'Work from home', 'Contractor...   \n",
       "2  ['12 hours ago', '10â€“46 an hour', 'Work from h...   \n",
       "3  ['14 hours ago', '8â€“15 an hour', 'Work from ho...   \n",
       "4  ['16 hours ago', '82,800â€“106,425 a year', 'Wor...   \n",
       "\n",
       "                                              job_id  \\\n",
       "0  eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBBbmFseXN0Ii...   \n",
       "1  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c2lzIiwiaHRpZG...   \n",
       "2  eyJqb2JfdGl0bGUiOiJHb29nbGUgQW5hbHl0aWNzIEdBNC...   \n",
       "3  eyJqb2JfdGl0bGUiOiJEYXRhIGFuYWx5c3Qgc3FsIGFuZC...   \n",
       "4  eyJqb2JfdGl0bGUiOiJSZXBvcnRpbmcgYW5kIERhdGEgRW...   \n",
       "\n",
       "                                           thumbnail  ... salary_avg  \\\n",
       "0  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...        NaN   \n",
       "1                                                NaN  ...        NaN   \n",
       "2                                                NaN  ...       28.0   \n",
       "3                                                NaN  ...       11.5   \n",
       "4  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...    94612.5   \n",
       "\n",
       "  salary_min salary_max salary_hourly salary_yearly salary_standardized  \\\n",
       "0        NaN        NaN           NaN           NaN                 NaN   \n",
       "1        NaN        NaN           NaN           NaN                 NaN   \n",
       "2       10.0       46.0          28.0           NaN             58240.0   \n",
       "3        8.0       15.0          11.5           NaN             23920.0   \n",
       "4    82800.0   106425.0           NaN       94612.5             94612.5   \n",
       "\n",
       "                                  description_tokens  \\\n",
       "0  ['excel', 'bigquery', 'redshift', 'sql', 'powe...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                   ['excel', 'sql']   \n",
       "4  ['jira', 'python', 'atlassian', 'snowflake', '...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  Our Client is looking for a fulltime Sr Data A...   \n",
       "1  We are seeking a skilled data analyst to join ...   \n",
       "2  We are seeking a skilled professional to adjus...   \n",
       "3  Its totally about data analysis and looking fo...   \n",
       "4  As a leading mountain resort operator with ove...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['Our', 'C', '##lient', 'is', 'looking', 'for'...   \n",
       "1  ['We', 'are', 'seeking', 'a', 'skilled', 'data...   \n",
       "2  ['We', 'are', 'seeking', 'a', 'skilled', 'prof...   \n",
       "3  ['Its', 'totally', 'about', 'data', 'analysis'...   \n",
       "4  ['As', 'a', 'leading', 'mountain', 'resort', '...   \n",
       "\n",
       "                                         ner_results  \n",
       "0  [{'entity': 'B-MISC', 'score': 0.6366868, 'ind...  \n",
       "1                                                 []  \n",
       "2  [{'entity': 'B-MISC', 'score': 0.8648094, 'ind...  \n",
       "3  [{'entity': 'B-MISC', 'score': 0.8927205, 'ind...  \n",
       "4  [{'entity': 'B-MISC', 'score': 0.63972175, 'in...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>26572.0</td>\n",
       "      <td>18958.853116</td>\n",
       "      <td>10955.638068</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9489.75</td>\n",
       "      <td>18913.5</td>\n",
       "      <td>28443.25</td>\n",
       "      <td>37959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>26572.0</td>\n",
       "      <td>1123.900497</td>\n",
       "      <td>708.459680</td>\n",
       "      <td>0.00</td>\n",
       "      <td>534.00</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>1641.00</td>\n",
       "      <td>3537.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commute_time</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_avg</th>\n",
       "      <td>4553.0</td>\n",
       "      <td>34627.321422</td>\n",
       "      <td>51257.459590</td>\n",
       "      <td>7.25</td>\n",
       "      <td>30.00</td>\n",
       "      <td>57.5</td>\n",
       "      <td>85000.00</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_min</th>\n",
       "      <td>4283.0</td>\n",
       "      <td>28934.018394</td>\n",
       "      <td>43007.870333</td>\n",
       "      <td>8.00</td>\n",
       "      <td>18.33</td>\n",
       "      <td>40.0</td>\n",
       "      <td>74300.00</td>\n",
       "      <td>275000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_max</th>\n",
       "      <td>4283.0</td>\n",
       "      <td>40824.664466</td>\n",
       "      <td>60594.691036</td>\n",
       "      <td>10.00</td>\n",
       "      <td>42.60</td>\n",
       "      <td>75.0</td>\n",
       "      <td>100000.00</td>\n",
       "      <td>325000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_hourly</th>\n",
       "      <td>2995.0</td>\n",
       "      <td>41.637621</td>\n",
       "      <td>22.758898</td>\n",
       "      <td>7.25</td>\n",
       "      <td>25.00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>57.50</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_yearly</th>\n",
       "      <td>1550.0</td>\n",
       "      <td>101600.679471</td>\n",
       "      <td>30259.611520</td>\n",
       "      <td>30000.00</td>\n",
       "      <td>85000.00</td>\n",
       "      <td>96500.0</td>\n",
       "      <td>112500.00</td>\n",
       "      <td>300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_standardized</th>\n",
       "      <td>4553.0</td>\n",
       "      <td>91696.906686</td>\n",
       "      <td>42855.061688</td>\n",
       "      <td>15080.00</td>\n",
       "      <td>62400.00</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>115440.00</td>\n",
       "      <td>624000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count           mean           std       min       25%  \\\n",
       "Unnamed: 0           26572.0   18958.853116  10955.638068      5.00   9489.75   \n",
       "index                26572.0    1123.900497    708.459680      0.00    534.00   \n",
       "commute_time             0.0            NaN           NaN       NaN       NaN   \n",
       "salary_avg            4553.0   34627.321422  51257.459590      7.25     30.00   \n",
       "salary_min            4283.0   28934.018394  43007.870333      8.00     18.33   \n",
       "salary_max            4283.0   40824.664466  60594.691036     10.00     42.60   \n",
       "salary_hourly         2995.0      41.637621     22.758898      7.25     25.00   \n",
       "salary_yearly         1550.0  101600.679471  30259.611520  30000.00  85000.00   \n",
       "salary_standardized   4553.0   91696.906686  42855.061688  15080.00  62400.00   \n",
       "\n",
       "                         50%        75%       max  \n",
       "Unnamed: 0           18913.5   28443.25   37959.0  \n",
       "index                 1085.0    1641.00    3537.0  \n",
       "commute_time             NaN        NaN       NaN  \n",
       "salary_avg              57.5   85000.00  300000.0  \n",
       "salary_min              40.0   74300.00  275000.0  \n",
       "salary_max              75.0  100000.00  325000.0  \n",
       "salary_hourly           35.0      57.50     300.0  \n",
       "salary_yearly        96500.0  112500.00  300000.0  \n",
       "salary_standardized  90000.0  115440.00  624000.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing dataset:\n",
      "Shape: (7593, 30)\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>via</th>\n",
       "      <th>description</th>\n",
       "      <th>extensions</th>\n",
       "      <th>job_id</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>...</th>\n",
       "      <th>salary_avg</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "      <th>salary_hourly</th>\n",
       "      <th>salary_yearly</th>\n",
       "      <th>salary_standardized</th>\n",
       "      <th>description_tokens</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24661</td>\n",
       "      <td>1220</td>\n",
       "      <td>Developer needed for data analysis</td>\n",
       "      <td>Upwork</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via Upwork</td>\n",
       "      <td>I am looking for a python programmer to find o...</td>\n",
       "      <td>['4 hours ago', 'Work from home', 'Contractor']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEZXZlbG9wZXIgbmVlZGVkIGZvci...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['python']</td>\n",
       "      <td>I am looking for a python programmer to find o...</td>\n",
       "      <td>['I', 'am', 'looking', 'for', 'a', 'p', '##yt'...</td>\n",
       "      <td>[{'entity': 'B-MISC', 'score': 0.49905413, 'in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2551</td>\n",
       "      <td>517</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Humana</td>\n",
       "      <td>Overland Park, KS</td>\n",
       "      <td>via BeBee</td>\n",
       "      <td>Description\\nHumana's Clinical Pharmacy Review...</td>\n",
       "      <td>['8 hours ago', 'Full-time', 'No degree mentio...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBBbmFseXN0Ii...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['excel', 'power_bi', 'sql', 'sas', 'azure', '...</td>\n",
       "      <td>Description\\nHumanas Clinical Pharmacy Review ...</td>\n",
       "      <td>['Des', '##cription', 'Human', '##as', 'Clinic...</td>\n",
       "      <td>[{'entity': 'B-ORG', 'score': 0.9582342, 'inde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37053</td>\n",
       "      <td>1399</td>\n",
       "      <td>Senior Data Analyst Business Optimization Inte...</td>\n",
       "      <td>Cox Communications</td>\n",
       "      <td>Warr Acres, OK</td>\n",
       "      <td>via ZipRecruiter</td>\n",
       "      <td>Senior Data Analyst\\n\\nThe Consumer Analytics ...</td>\n",
       "      <td>['18 hours ago', '77Kâ€“116K a year', 'Full-time...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBBbmFseXN0IE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>96500.0</td>\n",
       "      <td>77000.0</td>\n",
       "      <td>116000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96500.0</td>\n",
       "      <td>96500.0</td>\n",
       "      <td>['snowflake', 'tableau', 'excel', 'sql', 'aws'...</td>\n",
       "      <td>Senior Data Analyst\\n\\nThe Consumer Analytics ...</td>\n",
       "      <td>['Senior', 'Data', 'Ana', '##ly', '##st', 'The...</td>\n",
       "      <td>[{'entity': 'B-ORG', 'score': 0.76681745, 'ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6295</td>\n",
       "      <td>46</td>\n",
       "      <td>Database Analyst</td>\n",
       "      <td>Professional Diversity Network</td>\n",
       "      <td>United States</td>\n",
       "      <td>via Jobs Trabajo.org</td>\n",
       "      <td>The National Institute of Nursing Research, De...</td>\n",
       "      <td>['11 hours ago', 'Full-time and Part-time']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhYmFzZSBBbmFseXN0IiwiaH...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['excel']</td>\n",
       "      <td>The National Institute of Nursing Research Dep...</td>\n",
       "      <td>['The', 'National', 'Institute', 'of', 'Nursin...</td>\n",
       "      <td>[{'entity': 'B-ORG', 'score': 0.9987381, 'inde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20002</td>\n",
       "      <td>397</td>\n",
       "      <td>Workday Reporting/Data Analyst</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>Kansas City, MO</td>\n",
       "      <td>via WREG Jobs</td>\n",
       "      <td>You could be the one who changes everything fo...</td>\n",
       "      <td>['13 hours ago', 'Full-time', 'Health insuranc...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJXb3JrZGF5IFJlcG9ydGluZy9EYX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['excel']</td>\n",
       "      <td>You could be the one who changes everything fo...</td>\n",
       "      <td>['You', 'could', 'be', 'the', 'one', 'who', 'c...</td>\n",
       "      <td>[{'entity': 'B-ORG', 'score': 0.95291924, 'ind...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                                              title  \\\n",
       "0       24661   1220                 Developer needed for data analysis   \n",
       "1        2551    517                                Senior Data Analyst   \n",
       "2       37053   1399  Senior Data Analyst Business Optimization Inte...   \n",
       "3        6295     46                                   Database Analyst   \n",
       "4       20002    397                     Workday Reporting/Data Analyst   \n",
       "\n",
       "                     company_name                location  \\\n",
       "0                          Upwork                Anywhere   \n",
       "1                          Humana    Overland Park, KS      \n",
       "2              Cox Communications          Warr Acres, OK   \n",
       "3  Professional Diversity Network        United States      \n",
       "4                       Corporate         Kansas City, MO   \n",
       "\n",
       "                    via                                        description  \\\n",
       "0            via Upwork  I am looking for a python programmer to find o...   \n",
       "1             via BeBee  Description\\nHumana's Clinical Pharmacy Review...   \n",
       "2      via ZipRecruiter  Senior Data Analyst\\n\\nThe Consumer Analytics ...   \n",
       "3  via Jobs Trabajo.org  The National Institute of Nursing Research, De...   \n",
       "4         via WREG Jobs  You could be the one who changes everything fo...   \n",
       "\n",
       "                                          extensions  \\\n",
       "0    ['4 hours ago', 'Work from home', 'Contractor']   \n",
       "1  ['8 hours ago', 'Full-time', 'No degree mentio...   \n",
       "2  ['18 hours ago', '77Kâ€“116K a year', 'Full-time...   \n",
       "3        ['11 hours ago', 'Full-time and Part-time']   \n",
       "4  ['13 hours ago', 'Full-time', 'Health insuranc...   \n",
       "\n",
       "                                              job_id  \\\n",
       "0  eyJqb2JfdGl0bGUiOiJEZXZlbG9wZXIgbmVlZGVkIGZvci...   \n",
       "1  eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBBbmFseXN0Ii...   \n",
       "2  eyJqb2JfdGl0bGUiOiJTZW5pb3IgRGF0YSBBbmFseXN0IE...   \n",
       "3  eyJqb2JfdGl0bGUiOiJEYXRhYmFzZSBBbmFseXN0IiwiaH...   \n",
       "4  eyJqb2JfdGl0bGUiOiJXb3JrZGF5IFJlcG9ydGluZy9EYX...   \n",
       "\n",
       "                                           thumbnail  ... salary_avg  \\\n",
       "0                                                NaN  ...        NaN   \n",
       "1  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...        NaN   \n",
       "2                                                NaN  ...    96500.0   \n",
       "3  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...        NaN   \n",
       "4                                                NaN  ...        NaN   \n",
       "\n",
       "  salary_min salary_max salary_hourly salary_yearly salary_standardized  \\\n",
       "0        NaN        NaN           NaN           NaN                 NaN   \n",
       "1        NaN        NaN           NaN           NaN                 NaN   \n",
       "2    77000.0   116000.0           NaN       96500.0             96500.0   \n",
       "3        NaN        NaN           NaN           NaN                 NaN   \n",
       "4        NaN        NaN           NaN           NaN                 NaN   \n",
       "\n",
       "                                  description_tokens  \\\n",
       "0                                         ['python']   \n",
       "1  ['excel', 'power_bi', 'sql', 'sas', 'azure', '...   \n",
       "2  ['snowflake', 'tableau', 'excel', 'sql', 'aws'...   \n",
       "3                                          ['excel']   \n",
       "4                                          ['excel']   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  I am looking for a python programmer to find o...   \n",
       "1  Description\\nHumanas Clinical Pharmacy Review ...   \n",
       "2  Senior Data Analyst\\n\\nThe Consumer Analytics ...   \n",
       "3  The National Institute of Nursing Research Dep...   \n",
       "4  You could be the one who changes everything fo...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['I', 'am', 'looking', 'for', 'a', 'p', '##yt'...   \n",
       "1  ['Des', '##cription', 'Human', '##as', 'Clinic...   \n",
       "2  ['Senior', 'Data', 'Ana', '##ly', '##st', 'The...   \n",
       "3  ['The', 'National', 'Institute', 'of', 'Nursin...   \n",
       "4  ['You', 'could', 'be', 'the', 'one', 'who', 'c...   \n",
       "\n",
       "                                         ner_results  \n",
       "0  [{'entity': 'B-MISC', 'score': 0.49905413, 'in...  \n",
       "1  [{'entity': 'B-ORG', 'score': 0.9582342, 'inde...  \n",
       "2  [{'entity': 'B-ORG', 'score': 0.76681745, 'ind...  \n",
       "3  [{'entity': 'B-ORG', 'score': 0.9987381, 'inde...  \n",
       "4  [{'entity': 'B-ORG', 'score': 0.95291924, 'ind...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>7593.0</td>\n",
       "      <td>19062.314764</td>\n",
       "      <td>10979.762010</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9518.000</td>\n",
       "      <td>19194.0</td>\n",
       "      <td>28694.00</td>\n",
       "      <td>37961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>7593.0</td>\n",
       "      <td>1116.569999</td>\n",
       "      <td>713.000206</td>\n",
       "      <td>0.00</td>\n",
       "      <td>510.000</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>1640.00</td>\n",
       "      <td>3538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commute_time</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_avg</th>\n",
       "      <td>1335.0</td>\n",
       "      <td>34942.596213</td>\n",
       "      <td>52804.063810</td>\n",
       "      <td>9.00</td>\n",
       "      <td>30.750</td>\n",
       "      <td>57.5</td>\n",
       "      <td>82425.25</td>\n",
       "      <td>288000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_min</th>\n",
       "      <td>1269.0</td>\n",
       "      <td>29830.359716</td>\n",
       "      <td>44850.024114</td>\n",
       "      <td>8.00</td>\n",
       "      <td>18.460</td>\n",
       "      <td>40.0</td>\n",
       "      <td>71458.00</td>\n",
       "      <td>230000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_max</th>\n",
       "      <td>1269.0</td>\n",
       "      <td>41568.706706</td>\n",
       "      <td>62536.048858</td>\n",
       "      <td>10.00</td>\n",
       "      <td>45.000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>96994.00</td>\n",
       "      <td>346000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_hourly</th>\n",
       "      <td>881.0</td>\n",
       "      <td>43.018303</td>\n",
       "      <td>22.109509</td>\n",
       "      <td>9.00</td>\n",
       "      <td>25.000</td>\n",
       "      <td>37.5</td>\n",
       "      <td>57.50</td>\n",
       "      <td>137.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_yearly</th>\n",
       "      <td>450.0</td>\n",
       "      <td>103526.247378</td>\n",
       "      <td>34242.195253</td>\n",
       "      <td>29289.84</td>\n",
       "      <td>80996.375</td>\n",
       "      <td>96500.0</td>\n",
       "      <td>119875.00</td>\n",
       "      <td>288000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_standardized</th>\n",
       "      <td>1335.0</td>\n",
       "      <td>94157.945558</td>\n",
       "      <td>42843.862362</td>\n",
       "      <td>18720.00</td>\n",
       "      <td>62400.000</td>\n",
       "      <td>93600.0</td>\n",
       "      <td>119600.00</td>\n",
       "      <td>288000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count           mean           std       min        25%  \\\n",
       "Unnamed: 0           7593.0   19062.314764  10979.762010      1.00   9518.000   \n",
       "index                7593.0    1116.569999    713.000206      0.00    510.000   \n",
       "commute_time            0.0            NaN           NaN       NaN        NaN   \n",
       "salary_avg           1335.0   34942.596213  52804.063810      9.00     30.750   \n",
       "salary_min           1269.0   29830.359716  44850.024114      8.00     18.460   \n",
       "salary_max           1269.0   41568.706706  62536.048858     10.00     45.000   \n",
       "salary_hourly         881.0      43.018303     22.109509      9.00     25.000   \n",
       "salary_yearly         450.0  103526.247378  34242.195253  29289.84  80996.375   \n",
       "salary_standardized  1335.0   94157.945558  42843.862362  18720.00  62400.000   \n",
       "\n",
       "                         50%        75%       max  \n",
       "Unnamed: 0           19194.0   28694.00   37961.0  \n",
       "index                 1073.0    1640.00    3538.0  \n",
       "commute_time             NaN        NaN       NaN  \n",
       "salary_avg              57.5   82425.25  288000.0  \n",
       "salary_min              40.0   71458.00  230000.0  \n",
       "salary_max              75.0   96994.00  346000.0  \n",
       "salary_hourly           37.5      57.50     137.5  \n",
       "salary_yearly        96500.0  119875.00  288000.0  \n",
       "salary_standardized  93600.0  119600.00  288000.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation dataset:\n",
      "Shape: (3797, 30)\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>via</th>\n",
       "      <th>description</th>\n",
       "      <th>extensions</th>\n",
       "      <th>job_id</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>...</th>\n",
       "      <th>salary_avg</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "      <th>salary_hourly</th>\n",
       "      <th>salary_yearly</th>\n",
       "      <th>salary_standardized</th>\n",
       "      <th>description_tokens</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18784</td>\n",
       "      <td>1256</td>\n",
       "      <td>(USA) Senior Manager, Data Analytics</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Noel, MO</td>\n",
       "      <td>via ZipRecruiter</td>\n",
       "      <td>Position Summary...\\n\\nWhat you'll do...\\n\\nDa...</td>\n",
       "      <td>['18 hours ago', 'Full-time']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiIoVVNBKSBTZW5pb3IgTWFuYWdlci...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['python', 'matplotlib', 'spark', 'scala', 'ta...</td>\n",
       "      <td>Position Summary\\n\\nWhat youll do\\n\\nData Sour...</td>\n",
       "      <td>['Po', '##si', '##tion', 'Su', '##mma', '##ry'...</td>\n",
       "      <td>[{'entity': 'B-MISC', 'score': 0.99187624, 'in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8165</td>\n",
       "      <td>1916</td>\n",
       "      <td>Data Engineer â€“ Unstructured Data</td>\n",
       "      <td>ECS</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>ECS is seeking a Data Engineer to work Remotel...</td>\n",
       "      <td>['16 hours ago', 'Work from home', 'Full-time']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIOKAkyBVbn...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['python', 'tableau', 'git', 'power_bi']</td>\n",
       "      <td>ECS is seeking a Data Engineer to work Remotel...</td>\n",
       "      <td>['EC', '##S', 'is', 'seeking', 'a', 'Data', 'E...</td>\n",
       "      <td>[{'entity': 'B-ORG', 'score': 0.99776936, 'ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8589</td>\n",
       "      <td>20</td>\n",
       "      <td>Analyst II, Data Analytics</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>United States</td>\n",
       "      <td>via Trabajo.org</td>\n",
       "      <td>Position Summary...\\n\\nWhat you'll do...\\n\\nUn...</td>\n",
       "      <td>['7 hours ago', 'Full-time']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJBbmFseXN0IElJLCBEYXRhIEFuYW...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['python', 'matplotlib', 'spark', 'scala', 'ta...</td>\n",
       "      <td>Position Summary\\n\\nWhat youll do\\n\\nUnderstan...</td>\n",
       "      <td>['Po', '##si', '##tion', 'Su', '##mma', '##ry'...</td>\n",
       "      <td>[{'entity': 'B-MISC', 'score': 0.9858797, 'ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34674</td>\n",
       "      <td>1014</td>\n",
       "      <td>Machine Learning Operations - Analyst REMOTE</td>\n",
       "      <td>Liberty Mutual Insurance</td>\n",
       "      <td>United States</td>\n",
       "      <td>via WANE Jobs</td>\n",
       "      <td>Note: This is a remote opportunity with compen...</td>\n",
       "      <td>['7 hours ago', '125Kâ€“165K a year', 'Full-time']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJNYWNoaW5lIExlYXJuaW5nIE9wZX...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Note This is a remote opportunity with compens...</td>\n",
       "      <td>['Note', 'This', 'is', 'a', 'remote', 'opportu...</td>\n",
       "      <td>[{'entity': 'B-ORG', 'score': 0.9906198, 'inde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11091</td>\n",
       "      <td>159</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Austin Artificial Intelligence, Inc.</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>We have an immediate need for skilled data sci...</td>\n",
       "      <td>['20 hours ago', 'Work from home', 'Full-time'...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCIsImh0aW...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['aws', 'sql', 'r', 'nosql', 'azure', 'python']</td>\n",
       "      <td>We have an immediate need for skilled data sci...</td>\n",
       "      <td>['We', 'have', 'an', 'immediate', 'need', 'for...</td>\n",
       "      <td>[{'entity': 'B-MISC', 'score': 0.9830434, 'ind...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                                         title  \\\n",
       "0       18784   1256          (USA) Senior Manager, Data Analytics   \n",
       "1        8165   1916             Data Engineer â€“ Unstructured Data   \n",
       "2        8589     20                    Analyst II, Data Analytics   \n",
       "3       34674   1014  Machine Learning Operations - Analyst REMOTE   \n",
       "4       11091    159                                Data Scientist   \n",
       "\n",
       "                           company_name            location               via  \\\n",
       "0                               Walmart         Noel, MO     via ZipRecruiter   \n",
       "1                                   ECS           Anywhere       via LinkedIn   \n",
       "2                               Walmart    United States      via Trabajo.org   \n",
       "3              Liberty Mutual Insurance       United States     via WANE Jobs   \n",
       "4  Austin Artificial Intelligence, Inc.           Anywhere       via LinkedIn   \n",
       "\n",
       "                                         description  \\\n",
       "0  Position Summary...\\n\\nWhat you'll do...\\n\\nDa...   \n",
       "1  ECS is seeking a Data Engineer to work Remotel...   \n",
       "2  Position Summary...\\n\\nWhat you'll do...\\n\\nUn...   \n",
       "3  Note: This is a remote opportunity with compen...   \n",
       "4  We have an immediate need for skilled data sci...   \n",
       "\n",
       "                                          extensions  \\\n",
       "0                      ['18 hours ago', 'Full-time']   \n",
       "1    ['16 hours ago', 'Work from home', 'Full-time']   \n",
       "2                       ['7 hours ago', 'Full-time']   \n",
       "3   ['7 hours ago', '125Kâ€“165K a year', 'Full-time']   \n",
       "4  ['20 hours ago', 'Work from home', 'Full-time'...   \n",
       "\n",
       "                                              job_id  \\\n",
       "0  eyJqb2JfdGl0bGUiOiIoVVNBKSBTZW5pb3IgTWFuYWdlci...   \n",
       "1  eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIOKAkyBVbn...   \n",
       "2  eyJqb2JfdGl0bGUiOiJBbmFseXN0IElJLCBEYXRhIEFuYW...   \n",
       "3  eyJqb2JfdGl0bGUiOiJNYWNoaW5lIExlYXJuaW5nIE9wZX...   \n",
       "4  eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCIsImh0aW...   \n",
       "\n",
       "                                           thumbnail  ... salary_avg  \\\n",
       "0  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...        NaN   \n",
       "1  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...        NaN   \n",
       "2  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...        NaN   \n",
       "3  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...   145000.0   \n",
       "4  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...        NaN   \n",
       "\n",
       "  salary_min salary_max salary_hourly salary_yearly salary_standardized  \\\n",
       "0        NaN        NaN           NaN           NaN                 NaN   \n",
       "1        NaN        NaN           NaN           NaN                 NaN   \n",
       "2        NaN        NaN           NaN           NaN                 NaN   \n",
       "3   125000.0   165000.0           NaN      145000.0            145000.0   \n",
       "4        NaN        NaN           NaN           NaN                 NaN   \n",
       "\n",
       "                                  description_tokens  \\\n",
       "0  ['python', 'matplotlib', 'spark', 'scala', 'ta...   \n",
       "1           ['python', 'tableau', 'git', 'power_bi']   \n",
       "2  ['python', 'matplotlib', 'spark', 'scala', 'ta...   \n",
       "3                                                 []   \n",
       "4    ['aws', 'sql', 'r', 'nosql', 'azure', 'python']   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  Position Summary\\n\\nWhat youll do\\n\\nData Sour...   \n",
       "1  ECS is seeking a Data Engineer to work Remotel...   \n",
       "2  Position Summary\\n\\nWhat youll do\\n\\nUnderstan...   \n",
       "3  Note This is a remote opportunity with compens...   \n",
       "4  We have an immediate need for skilled data sci...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['Po', '##si', '##tion', 'Su', '##mma', '##ry'...   \n",
       "1  ['EC', '##S', 'is', 'seeking', 'a', 'Data', 'E...   \n",
       "2  ['Po', '##si', '##tion', 'Su', '##mma', '##ry'...   \n",
       "3  ['Note', 'This', 'is', 'a', 'remote', 'opportu...   \n",
       "4  ['We', 'have', 'an', 'immediate', 'need', 'for...   \n",
       "\n",
       "                                         ner_results  \n",
       "0  [{'entity': 'B-MISC', 'score': 0.99187624, 'in...  \n",
       "1  [{'entity': 'B-ORG', 'score': 0.99776936, 'ind...  \n",
       "2  [{'entity': 'B-MISC', 'score': 0.9858797, 'ind...  \n",
       "3  [{'entity': 'B-ORG', 'score': 0.9906198, 'inde...  \n",
       "4  [{'entity': 'B-MISC', 'score': 0.9830434, 'ind...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>3797.0</td>\n",
       "      <td>18968.380300</td>\n",
       "      <td>10941.369180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9433.0</td>\n",
       "      <td>19045.00</td>\n",
       "      <td>28196.0000</td>\n",
       "      <td>37948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>3797.0</td>\n",
       "      <td>1113.846721</td>\n",
       "      <td>718.977397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>1070.00</td>\n",
       "      <td>1622.0000</td>\n",
       "      <td>3527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commute_time</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_avg</th>\n",
       "      <td>639.0</td>\n",
       "      <td>33166.161557</td>\n",
       "      <td>51542.877739</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>57.50</td>\n",
       "      <td>77500.0000</td>\n",
       "      <td>221875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_min</th>\n",
       "      <td>604.0</td>\n",
       "      <td>28400.635199</td>\n",
       "      <td>44247.965213</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>68740.6425</td>\n",
       "      <td>185000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_max</th>\n",
       "      <td>604.0</td>\n",
       "      <td>39216.039189</td>\n",
       "      <td>60547.790213</td>\n",
       "      <td>12.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>90100.0000</td>\n",
       "      <td>258750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_hourly</th>\n",
       "      <td>430.0</td>\n",
       "      <td>44.489953</td>\n",
       "      <td>24.265912</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>39.25</td>\n",
       "      <td>57.5000</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_yearly</th>\n",
       "      <td>207.0</td>\n",
       "      <td>102227.323937</td>\n",
       "      <td>33741.382692</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>79930.0</td>\n",
       "      <td>96500.00</td>\n",
       "      <td>114750.0000</td>\n",
       "      <td>221875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_standardized</th>\n",
       "      <td>639.0</td>\n",
       "      <td>95631.856737</td>\n",
       "      <td>45849.053301</td>\n",
       "      <td>20800.0</td>\n",
       "      <td>63960.0</td>\n",
       "      <td>91520.00</td>\n",
       "      <td>119600.0000</td>\n",
       "      <td>468000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count           mean           std      min      25%  \\\n",
       "Unnamed: 0           3797.0   18968.380300  10941.369180      0.0   9433.0   \n",
       "index                3797.0    1113.846721    718.977397      0.0    513.0   \n",
       "commute_time            0.0            NaN           NaN      NaN      NaN   \n",
       "salary_avg            639.0   33166.161557  51542.877739     10.0     32.5   \n",
       "salary_min            604.0   28400.635199  44247.965213      8.0     20.0   \n",
       "salary_max            604.0   39216.039189  60547.790213     12.0     45.0   \n",
       "salary_hourly         430.0      44.489953     24.265912     10.0     27.5   \n",
       "salary_yearly         207.0  102227.323937  33741.382692  45000.0  79930.0   \n",
       "salary_standardized   639.0   95631.856737  45849.053301  20800.0  63960.0   \n",
       "\n",
       "                          50%          75%       max  \n",
       "Unnamed: 0           19045.00   28196.0000   37948.0  \n",
       "index                 1070.00    1622.0000    3527.0  \n",
       "commute_time              NaN          NaN       NaN  \n",
       "salary_avg              57.50   77500.0000  221875.0  \n",
       "salary_min              40.00   68740.6425  185000.0  \n",
       "salary_max              75.00   90100.0000  258750.0  \n",
       "salary_hourly           39.25      57.5000     225.0  \n",
       "salary_yearly        96500.00  114750.0000  221875.0  \n",
       "salary_standardized  91520.00  119600.0000  468000.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def load_and_inspect_transformed_data(train_path, test_path, val_path):\n",
    "    \"\"\"\n",
    "    Loads the transformed datasets from specified paths and displays their basic information\n",
    "    using IPython's display function for a more interactive visualization.\n",
    "    \n",
    "    Args:\n",
    "        train_path (str): Path to the training dataset CSV.\n",
    "        test_path (str): Path to the testing dataset CSV.\n",
    "        val_path (str): Path to the validation dataset CSV.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load datasets\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    val_df = pd.read_csv(val_path)\n",
    "    \n",
    "    # Inspect each dataset\n",
    "    for name, df in zip([\"Training\", \"Testing\", \"Validation\"], [train_df, test_df, val_df]):\n",
    "        print(f\"\\n{name} dataset:\")\n",
    "        print(f\"Shape: {df.shape}\")\n",
    "        print(\"First 5 rows:\")\n",
    "        display(df.head())\n",
    "        print(\"\\nBasic statistics:\")\n",
    "        display(df.describe().transpose())\n",
    "        # Add more analysis or visualization as needed\n",
    "\n",
    "# Example usage\n",
    "train_path = 'artifacts/data_transformation/train_data.csv'\n",
    "test_path = 'artifacts/data_transformation/test_data.csv'\n",
    "val_path = 'artifacts/data_transformation/val_data.csv'\n",
    "\n",
    "load_and_inspect_transformed_data(train_path, test_path, val_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "career_chief_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
