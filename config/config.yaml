# Root directory for all artifacts
artifacts_root: artifacts

# Configuration related to data ingestion
data_ingestion:

  # Directory where data ingestion artifacts are stored
  root_dir: artifacts/data_ingestion

  # Path to the local file where the data is already saved
  local_data_file: /Users/macbookpro/Documents/Documents - Macbookâ€™s MacBook Pro/thesis/thesis/data/gsearch_jobs.csv


# Configuration related to data validation
data_validation:
  # Directory where data validation results and artifacts are stored
  root_dir: artifacts/data_validation
  
  # Path to the ingested data file that will be used for validation
  data_source_file: artifacts/data_ingestion/gsearch_jobs.csv
  
  # Path to the file that captures the validation status (e.g., success, errors encountered)
  status_file: artifacts/data_validation/status.txt


# Configuration related to data transformation
data_transformation:
  # Directory where data transformation results and artifacts are stored
  root_dir: artifacts/data_transformation
  
  # Path to the ingested data file that will be used for validation
  data_source_file: artifacts/data_ingestion/gsearch_jobs.csv

  # Path to data validation status
  data_validation: artifacts/data_validation/status.txt

  # Path to normalization dictionary
  normalization_dict: artifacts/data_transformation/normalization_dict.json


# Configuration for spaCy Named Entity Recognition (NER) model training
spacy_ner:
  # Root directory for training artifacts
  root_dir: artifacts/model_training/spacy_ner

  # Path to annotated data
  json_annotated_path: artifacts/model_training/spacy_ner/project-4-at-2024-04-01-07-30-2333a63c.json  
 
  # Output path for the converted spaCy data
  output_path: artifacts/model_training/spacy_ner/output/converted_data.spacy  

  # Path to unannotated training data
  train_data_path: artifacts/data_transformation/train_data.csv  

  # Path to unannotated test data
  test_data_path: artifacts/data_transformation/test_data.csv  

  # Path to unannotated validation data
  val_data_path: artifacts/data_transformation/val_data.csv  

  # Processed spaCy training data
  spacy_train: artifacts/model_training/spacy_ner/output/train_data.spacy  

  # Processed spaCy dev (validation) data
  spacy_dev: artifacts/model_training/spacy_ner/output/dev_data.spacy  

  # GPU allocator (use 'pytorch' for PyTorch)
  gpu_allocator: pytorch  

  # NLP pipeline components
  components:  
    - name: "ner"
      factory: "ner"

  # Training parameters
  training:  
    batch_size: 128
    dropout: 0.5
    optimizer:
      learn_rate: 0.001
    patience: 3
    max_epochs: 20